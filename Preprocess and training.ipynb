{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required dependencies\n",
    "import pandas as pd\n",
    "from tensorflow.data import Dataset\n",
    "import os\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from preprocess import get_interesting_idx,load_data\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_encode = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_landmark_files/30680/1005102931.parquet</td>\n",
       "      <td>30680</td>\n",
       "      <td>1005102931</td>\n",
       "      <td>4</td>\n",
       "      <td>train_landmark_files/30680/1005102931.parquet$4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>train_landmark_files/22343/1006778422.parquet</td>\n",
       "      <td>22343</td>\n",
       "      <td>1006778422</td>\n",
       "      <td>1</td>\n",
       "      <td>train_landmark_files/22343/1006778422.parquet$1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>train_landmark_files/32319/1011764636.parquet</td>\n",
       "      <td>32319</td>\n",
       "      <td>1011764636</td>\n",
       "      <td>0</td>\n",
       "      <td>train_landmark_files/32319/1011764636.parquet$0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>train_landmark_files/37055/1011888729.parquet</td>\n",
       "      <td>37055</td>\n",
       "      <td>1011888729</td>\n",
       "      <td>1</td>\n",
       "      <td>train_landmark_files/37055/1011888729.parquet$1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>train_landmark_files/27610/1016834986.parquet</td>\n",
       "      <td>27610</td>\n",
       "      <td>1016834986</td>\n",
       "      <td>4</td>\n",
       "      <td>train_landmark_files/27610/1016834986.parquet$4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             path  participant_id  \\\n",
       "7   train_landmark_files/30680/1005102931.parquet           30680   \n",
       "11  train_landmark_files/22343/1006778422.parquet           22343   \n",
       "17  train_landmark_files/32319/1011764636.parquet           32319   \n",
       "18  train_landmark_files/37055/1011888729.parquet           37055   \n",
       "26  train_landmark_files/27610/1016834986.parquet           27610   \n",
       "\n",
       "    sequence_id  sign                                           source  \n",
       "7    1005102931     4  train_landmark_files/30680/1005102931.parquet$4  \n",
       "11   1006778422     1  train_landmark_files/22343/1006778422.parquet$1  \n",
       "17   1011764636     0  train_landmark_files/32319/1011764636.parquet$0  \n",
       "18   1011888729     1  train_landmark_files/37055/1011888729.parquet$1  \n",
       "26   1016834986     4  train_landmark_files/27610/1016834986.parquet$4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"19 action.xlsx\")\n",
    "data = data.query('sign == [\"thankyou\",\"happy\",\"hello\",\"mom\",\"dad\"]')\n",
    "od_encode.fit(data[['sign']])\n",
    "data['sign'] = od_encode.transform(data[[\"sign\"]])[:,0].astype(int)\n",
    "data['source'] = data['path'] + \"$\" +data['sign'].astype('str')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = data.sign.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(data['source'],data['sign'],test_size=0.2,random_state=10,stratify=data['sign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_val, y_test,y_val = train_test_split(X_test,y_test,test_size=0.5,random_state=10,stratify=y_test,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1519,)\n",
      "(190,)\n",
      "(190,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = get_interesting_idx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loarder(source):\n",
    "    source = source.numpy().decode()\n",
    "    ld = load_data(idx)\n",
    "    data,label = ld.load_relavent_data(source,n_class,\"$\")\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_function(source):\n",
    "    return tf.py_function(data_loarder,[source],(tf.float64,tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_tensor_slices(X_train)\n",
    "train_ds = train_ds.map(map_function)\n",
    "train_ds = train_ds.padded_batch(10,padded_shapes=([None,None,None],[n_class]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = Dataset.from_tensor_slices(X_test)\n",
    "test_ds = test_ds.map(map_function)\n",
    "test_ds = test_ds.padded_batch(10,padded_shapes=([None,None,None],[n_class]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = Dataset.from_tensor_slices(X_val)\n",
    "val_ds = val_ds.map(map_function)\n",
    "val_ds = val_ds.padded_batch(10,padded_shapes=([None,None,None],[n_class]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import add_residual_block,data_augmentation\n",
    "from tensorflow.keras.layers import Dropout,Conv2D,MaxPool2D,GlobalAveragePooling2D,Dense,BatchNormalization,ReLU\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs_1')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_shape = (None,160,80,3)\n",
    "Input = tf.keras.layers.Input(shape=Input_shape[1:])\n",
    "x = Input\n",
    "\n",
    "x = Conv2D(16,(3,3),padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "x = MaxPool2D(pool_size=(3,3),strides=(1,1))(x)\n",
    "\n",
    "x = data_augmentation()(x)\n",
    "\n",
    "#Block 1\n",
    "x = add_residual_block(x,16,(3,3))\n",
    "x = MaxPool2D(pool_size=(3,3),strides=(2,2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "# Block 2\n",
    "x = add_residual_block(x,32,(3,3))\n",
    "x = MaxPool2D(pool_size=(3,3),strides=(2,2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "#Block 3\n",
    "x = add_residual_block(x,32,(3,3))\n",
    "x = MaxPool2D(pool_size=(3,3),strides=(2,2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Conv2D(16,(3,3),padding='same')(x)\n",
    "x = MaxPool2D(pool_size=(3,3),strides=(2,2))(x)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(n_class,activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(Input,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 160, 80, 3)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 160, 80, 16)  448         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 160, 80, 16)  64         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 160, 80, 16)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 158, 78, 16)  0           ['re_lu[0][0]']                  \n",
      "                                                                                                  \n",
      " data_augmentation (data_augmen  (None, 158, 78, 16)  0          ['max_pooling2d[0][0]']          \n",
      " tation)                                                                                          \n",
      "                                                                                                  \n",
      " residual_main (Residual_main)  (None, 158, 78, 16)  4672        ['data_augmentation[0][0]']      \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 158, 78, 16)  0           ['data_augmentation[0][0]',      \n",
      "                                                                  'residual_main[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 78, 38, 16)  0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 78, 38, 16)   0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " project (project)              (None, 78, 38, 32)   608         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " residual_main_1 (Residual_main  (None, 78, 38, 32)  13952       ['dropout[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 78, 38, 32)   0           ['project[0][0]',                \n",
      "                                                                  'residual_main_1[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 38, 18, 32)  0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 38, 18, 32)   0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " residual_main_2 (Residual_main  (None, 38, 18, 32)  18560       ['dropout_1[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 38, 18, 32)   0           ['dropout_1[0][0]',              \n",
      "                                                                  'residual_main_2[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 18, 8, 32)   0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 18, 8, 32)    0           ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 18, 8, 16)    4624        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 8, 3, 16)    0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 16)          0           ['max_pooling2d_4[0][0]']        \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 5)            85          ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 43,013\n",
      "Trainable params: 42,981\n",
      "Non-trainable params: 32\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "Layer Residual_main has arguments ['filter', 'kernel_size']\n",
      "in `__init__` and therefore must override `get_config()`.\n",
      "\n",
      "Example:\n",
      "\n",
      "class CustomLayer(keras.layers.Layer):\n",
      "    def __init__(self, arg1, arg2):\n",
      "        super().__init__()\n",
      "        self.arg1 = arg1\n",
      "        self.arg2 = arg2\n",
      "\n",
      "    def get_config(self):\n",
      "        config = super().get_config()\n",
      "        config.update({\n",
      "            \"arg1\": self.arg1,\n",
      "            \"arg2\": self.arg2,\n",
      "        })\n",
      "        return config\n",
      "Epoch 1/50\n",
      "152/152 [==============================] - 25s 165ms/step - loss: 0.2225 - accuracy: 0.9203 - val_loss: 0.7276 - val_accuracy: 0.8158\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - 24s 155ms/step - loss: 0.2371 - accuracy: 0.9098 - val_loss: 0.7136 - val_accuracy: 0.8421\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - 25s 162ms/step - loss: 0.2097 - accuracy: 0.9157 - val_loss: 0.6481 - val_accuracy: 0.8421\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - 23s 154ms/step - loss: 0.2372 - accuracy: 0.9144 - val_loss: 0.6406 - val_accuracy: 0.8526\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - 25s 165ms/step - loss: 0.2056 - accuracy: 0.9315 - val_loss: 0.6407 - val_accuracy: 0.8474\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - 24s 159ms/step - loss: 0.2122 - accuracy: 0.9177 - val_loss: 0.7035 - val_accuracy: 0.8263\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - 24s 156ms/step - loss: 0.2133 - accuracy: 0.9269 - val_loss: 0.7075 - val_accuracy: 0.8316\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - 25s 165ms/step - loss: 0.2098 - accuracy: 0.9269 - val_loss: 0.7082 - val_accuracy: 0.8316\n",
      "Epoch 9/50\n",
      "152/152 [==============================] - 24s 158ms/step - loss: 0.2124 - accuracy: 0.9236 - val_loss: 0.6931 - val_accuracy: 0.8211\n",
      "Epoch 10/50\n",
      "152/152 [==============================] - 24s 156ms/step - loss: 0.2037 - accuracy: 0.9243 - val_loss: 0.6021 - val_accuracy: 0.8421\n",
      "Epoch 11/50\n",
      "152/152 [==============================] - 24s 159ms/step - loss: 0.2083 - accuracy: 0.9223 - val_loss: 0.6759 - val_accuracy: 0.8474\n",
      "Epoch 12/50\n",
      "152/152 [==============================] - 24s 155ms/step - loss: 0.2258 - accuracy: 0.9157 - val_loss: 0.7210 - val_accuracy: 0.8474\n",
      "Epoch 13/50\n",
      "152/152 [==============================] - 25s 161ms/step - loss: 0.2144 - accuracy: 0.9203 - val_loss: 0.7107 - val_accuracy: 0.8105\n",
      "Epoch 14/50\n",
      "152/152 [==============================] - 24s 157ms/step - loss: 0.2038 - accuracy: 0.9263 - val_loss: 0.7384 - val_accuracy: 0.8368\n",
      "Epoch 15/50\n",
      "152/152 [==============================] - 24s 156ms/step - loss: 0.1925 - accuracy: 0.9309 - val_loss: 0.8160 - val_accuracy: 0.8158\n",
      "Epoch 16/50\n",
      "152/152 [==============================] - 25s 163ms/step - loss: 0.2054 - accuracy: 0.9256 - val_loss: 0.7421 - val_accuracy: 0.8316\n",
      "Epoch 17/50\n",
      "152/152 [==============================] - 24s 155ms/step - loss: 0.2280 - accuracy: 0.9065 - val_loss: 0.8299 - val_accuracy: 0.8263\n",
      "Epoch 18/50\n",
      "152/152 [==============================] - 24s 155ms/step - loss: 0.2018 - accuracy: 0.9217 - val_loss: 0.7685 - val_accuracy: 0.8368\n",
      "Epoch 19/50\n",
      "152/152 [==============================] - 24s 159ms/step - loss: 0.2039 - accuracy: 0.9296 - val_loss: 0.7517 - val_accuracy: 0.8263\n",
      "Epoch 20/50\n",
      "152/152 [==============================] - 24s 160ms/step - loss: 0.1990 - accuracy: 0.9315 - val_loss: 0.7151 - val_accuracy: 0.8211\n",
      "Epoch 21/50\n",
      "152/152 [==============================] - 24s 158ms/step - loss: 0.2126 - accuracy: 0.9171 - val_loss: 0.8447 - val_accuracy: 0.8368\n",
      "Epoch 22/50\n",
      "152/152 [==============================] - 24s 156ms/step - loss: 0.1923 - accuracy: 0.9302 - val_loss: 0.7359 - val_accuracy: 0.8474\n",
      "Epoch 23/50\n",
      "152/152 [==============================] - 24s 158ms/step - loss: 0.1820 - accuracy: 0.9355 - val_loss: 0.7453 - val_accuracy: 0.8421\n",
      "Epoch 24/50\n",
      "152/152 [==============================] - 26s 170ms/step - loss: 0.1801 - accuracy: 0.9329 - val_loss: 0.6701 - val_accuracy: 0.8474\n",
      "Epoch 25/50\n",
      "152/152 [==============================] - 25s 162ms/step - loss: 0.2078 - accuracy: 0.9171 - val_loss: 0.7583 - val_accuracy: 0.8316\n",
      "Epoch 26/50\n",
      "152/152 [==============================] - 24s 154ms/step - loss: 0.2017 - accuracy: 0.9243 - val_loss: 0.8020 - val_accuracy: 0.8158\n",
      "Epoch 27/50\n",
      "152/152 [==============================] - 24s 157ms/step - loss: 0.2104 - accuracy: 0.9315 - val_loss: 0.8701 - val_accuracy: 0.8263\n",
      "Epoch 28/50\n",
      "152/152 [==============================] - 24s 158ms/step - loss: 0.1881 - accuracy: 0.9342 - val_loss: 0.8767 - val_accuracy: 0.8158\n",
      "Epoch 29/50\n",
      "152/152 [==============================] - 24s 157ms/step - loss: 0.1929 - accuracy: 0.9309 - val_loss: 0.7358 - val_accuracy: 0.8526\n",
      "Epoch 30/50\n",
      "152/152 [==============================] - 24s 158ms/step - loss: 0.1920 - accuracy: 0.9269 - val_loss: 0.7916 - val_accuracy: 0.8263\n",
      "Epoch 31/50\n",
      "152/152 [==============================] - 25s 164ms/step - loss: 0.2091 - accuracy: 0.9171 - val_loss: 0.8576 - val_accuracy: 0.8211\n",
      "Epoch 32/50\n",
      "152/152 [==============================] - 24s 157ms/step - loss: 0.1710 - accuracy: 0.9322 - val_loss: 0.7983 - val_accuracy: 0.8368\n",
      "Epoch 33/50\n",
      "152/152 [==============================] - 24s 157ms/step - loss: 0.1985 - accuracy: 0.9223 - val_loss: 0.8202 - val_accuracy: 0.8158\n",
      "Epoch 34/50\n",
      "152/152 [==============================] - 25s 165ms/step - loss: 0.2015 - accuracy: 0.9276 - val_loss: 0.7091 - val_accuracy: 0.8474\n",
      "Epoch 35/50\n",
      "152/152 [==============================] - 24s 157ms/step - loss: 0.1840 - accuracy: 0.9282 - val_loss: 0.7846 - val_accuracy: 0.8263\n",
      "Epoch 36/50\n",
      "152/152 [==============================] - 25s 164ms/step - loss: 0.1885 - accuracy: 0.9302 - val_loss: 0.7294 - val_accuracy: 0.8263\n",
      "Epoch 37/50\n",
      "152/152 [==============================] - 25s 164ms/step - loss: 0.1832 - accuracy: 0.9263 - val_loss: 0.7241 - val_accuracy: 0.8368\n",
      "Epoch 38/50\n",
      "152/152 [==============================] - 24s 157ms/step - loss: 0.1631 - accuracy: 0.9460 - val_loss: 0.7487 - val_accuracy: 0.8421\n",
      "Epoch 39/50\n",
      "152/152 [==============================] - 25s 164ms/step - loss: 0.1772 - accuracy: 0.9355 - val_loss: 0.7196 - val_accuracy: 0.8316\n",
      "Epoch 40/50\n",
      "152/152 [==============================] - 24s 160ms/step - loss: 0.1737 - accuracy: 0.9361 - val_loss: 0.8440 - val_accuracy: 0.8211\n",
      "Epoch 41/50\n",
      "152/152 [==============================] - 25s 167ms/step - loss: 0.1782 - accuracy: 0.9322 - val_loss: 0.9125 - val_accuracy: 0.8263\n",
      "Epoch 42/50\n",
      "152/152 [==============================] - 24s 157ms/step - loss: 0.1921 - accuracy: 0.9236 - val_loss: 0.8119 - val_accuracy: 0.8211\n",
      "Epoch 43/50\n",
      "152/152 [==============================] - 24s 157ms/step - loss: 0.1765 - accuracy: 0.9375 - val_loss: 0.8384 - val_accuracy: 0.8316\n",
      "Epoch 44/50\n",
      "152/152 [==============================] - 25s 167ms/step - loss: 0.2162 - accuracy: 0.9230 - val_loss: 0.8792 - val_accuracy: 0.8263\n",
      "Epoch 45/50\n",
      "152/152 [==============================] - 24s 159ms/step - loss: 0.1751 - accuracy: 0.9381 - val_loss: 0.7860 - val_accuracy: 0.8316\n",
      "Epoch 46/50\n",
      "152/152 [==============================] - 25s 164ms/step - loss: 0.1716 - accuracy: 0.9401 - val_loss: 0.8804 - val_accuracy: 0.8105\n",
      "Epoch 47/50\n",
      "152/152 [==============================] - 25s 164ms/step - loss: 0.1888 - accuracy: 0.9256 - val_loss: 0.8013 - val_accuracy: 0.8211\n",
      "Epoch 48/50\n",
      "152/152 [==============================] - 24s 155ms/step - loss: 0.1687 - accuracy: 0.9361 - val_loss: 0.8495 - val_accuracy: 0.8316\n",
      "Epoch 49/50\n",
      "152/152 [==============================] - 24s 156ms/step - loss: 0.1856 - accuracy: 0.9355 - val_loss: 0.9497 - val_accuracy: 0.8158\n",
      "Epoch 50/50\n",
      "152/152 [==============================] - 26s 168ms/step - loss: 0.1774 - accuracy: 0.9388 - val_loss: 0.8101 - val_accuracy: 0.8158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28420ef3a00>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds,epochs=50,validation_data=val_ds,callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 2s 84ms/step - loss: 0.7574 - accuracy: 0.8105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7573918104171753, 0.8105263113975525]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5_action_v2_acc_94_valacc_81\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5_action_v2_acc_94_valacc_81\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"5_action_v2_acc_94_valacc_81\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n"
     ]
    }
   ],
   "source": [
    "act_pred = []\n",
    "for values in test_ds:\n",
    "    y_pred = model.predict(values[0])\n",
    "    y_pred = list(map(lambda X:np.argmax(X),y_pred))\n",
    "    act = list(map(lambda X:np.argmax(X),values[1]))\n",
    "    for value in  zip(act,y_pred):\n",
    "        act_pred.append(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual  Predict\n",
       "0       2        2\n",
       "1       1        1\n",
       "2       1        1\n",
       "3       2        0\n",
       "4       3        3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = pd.DataFrame(act_pred,columns=[\"Actual\",\"Predict\"])\n",
    "evaluation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.97      0.77        38\n",
      "           1       0.79      0.79      0.79        38\n",
      "           2       1.00      0.72      0.84        39\n",
      "           3       1.00      0.82      0.90        40\n",
      "           4       0.79      0.74      0.76        35\n",
      "\n",
      "    accuracy                           0.81       190\n",
      "   macro avg       0.84      0.81      0.81       190\n",
      "weighted avg       0.85      0.81      0.81       190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(evaluation[\"Actual\"],evaluation[\"Predict\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAGdCAYAAAAczXrvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA37UlEQVR4nO3deXQUVdrH8V+TpQkhiYSQBQgRWRREVEAxgGwCmlEUcZBxQXBBkGXEyKsDqERnIKgjgoPizqJicENxIRLGSRADSIIMi4AgIKCEEHYC6Wz1/sFMnC62dOikevl+PHWOfau66sk90SfPvbeqbIZhGAIAAH6jltUBAACAmkXyBwDAz5D8AQDwMyR/AAD8DMkfAAA/Q/IHAMDPkPwBAPAzJH8AAPwMyR8AAD8TaHUA/1VSsM3qELxWSMNrrQ4BgIvsgUFWh+DVCo/vqNbzuzMnBUVd5LZzuYvHJH8AADxGeZnVEVQrhv0BAPAzVP4AAJgZ5VZHUK1I/gAAmJWT/AEA8CuGj1f+zPkDAOBnqPwBADBj2B8AAD/DsD8AAPAlVP4AAJj5+EN+SP4AAJgx7A8AAHwJlT8AAGas9gcAwL/wkB8AAFAjZs6cqbZt2yo8PFzh4eFKTEzUokWLKvYPGTJENpvNabvmmmtcvg6VPwAAZhYN+zdu3FhTpkxR8+bNJUlz5szRLbfcoh9++EGXXnqpJOmGG27QrFmzKr4THBzs8nVI/gAAmFk07N+3b1+nz5MmTdLMmTO1YsWKiuRvt9sVGxt7Xtdh2B8AALPyMvdtVVRWVqa0tDQVFhYqMTGxoj0zM1PR0dFq2bKlhg4dqvz8fJfPTeUPAEA1cjgccjgcTm12u112u/20x69bt06JiYkqKipS3bp1tWDBArVu3VqSlJSUpAEDBighIUHbt2/Xk08+qZ49eyo3N/eM5zsdm2EYRtV/JPcpKdhmdQheK6ThtVaHAMBF9sAgq0PwaoXHd1Tr+R0b/+W2c6XOz9LTTz/t1DZx4kSlpKSc9vji4mLt3LlThw4d0scff6w333xTWVlZFX8A/K89e/YoISFBaWlp6t+/f6VjIvn7AJI/4H1I/uen2pP/hn+672TNu7hU+Zv16tVLzZo102uvvXba/S1atNADDzygxx9/vNIhMewPAEA1ciXRn45hGKf88fBf+/fv165duxQXF+fSOUn+AACYWbTaf/z48UpKSlJ8fLyOHj2qtLQ0ZWZmKj09XceOHVNKSopuu+02xcXFaceOHRo/fryioqJ06623unQdkj8AAGYW3ee/d+9eDRo0SHv27FFERITatm2r9PR09e7dWydOnNC6des0d+5cHTp0SHFxcerRo4fmz5+vsLAwl67DnL8PYM4f8D7M+Z+fap/zX/u1285lb3u9287lLlT+AACYGEbV78/3BiR/AADMeLEPAADwJVT+AACYWbTgr6aQ/AEAMGPY3z+kLfhCt97zkDr27q+Ovfvrrgcf0bfLV1Xsb9M56bTb2+99ZGHUnm34sMHasnm5jh35WStXLFKXzldbHZJXof+qjr6rms6dr9aHH72prT+vVOHxHbqpbx+rQ7KOB7zYpzqR/P8jtkGUHhl+r+a/9ZLmv/WSrm5/uUb/5Rlt3faLJClz4XtO21/HPyKbzabe3TtbHLlnGjDgZk19IUWpU15Sh6uv17Jl3+uLz99VfHxDq0PzCvRf1dF3VRcaWkfr1m1UcvJTVoeCasZ9/mfR6YYBenTkA7qt76n3aP75L8+o8PhxvfXSFAsic+aJ9/lnL/tcq39Yr1Gjx1W0rVubqYUL0zXhCev7zNPRf1XnLX3n6ff5Fx7foYEDH9QXny+2OpTTqu77/Iu+/9Bt56p99QC3nctdXK78d+/erQkTJqhHjx5q1aqVWrdurR49emjChAnatWtXdcRY48rKyvTVkkydKCrSFW0uOWV/wYGDWpr9vfrf5HkPbvAEQUFBateurTKWZDm1Z2RkKfGaDhZF5T3ov6qj7+A25eXu2zyQSwv+li1bVvHM4T59+qhPnz4yDEP5+fn69NNP9Y9//EOLFi1S587eORT+08/bddewZBUXF6tOSIimT35SzZomnHLcwkVLVKdOiHp1886fs7pFRUUqMDBQ+XsLnNrz8wsUExttUVTeg/6rOvoOqByXkv8jjzyiBx54QC+++OIZ948ZM0arVq067f7/cjgcp7yhqJbDcV5vPXKHpk0a6+PZL+vI0WPKyPxOEya9oNkznjvlD4AFXyzWTX16yG4PtihS72CeUbLZbKe04czov6qj73DeWO3/u/Xr12v48OFn3D9s2DCtX7/+nOdJTU1VRESE0/bs9FddCaVaBAUFqUnjhmrTqqUeeeheXdz8Ir374WdOx+SuWa/tO3erf98bLIrS8xUUHFBpaaliYhs4tTdoUF/5e/dZFJX3oP+qjr6D2/j4sL9LyT8uLk7Z2dln3L98+fJKvVN43LhxOnz4sNP2+MNn/qPCKoZhqLi4xKntky++VuuLW+iSFhdZFJXnKykp0erVa9Xruq5O7b16ddXyFTkWReU96L+qo++AynFp2H/s2LEaPny4cnNz1bt3b8XExMhmsykvL08ZGRl68803NW3atHOex263nzLEX1JccIaja8a0V2fr2ms6KDamgQqPH9eiJVla9cM6vfrCXyuOOVZYqMX/+lZjRw21MFLv8OL0NzRn1nTl5v5bK1bmauj9d6tJfCO99vo7VofmFei/qqPvqi40tI6aNbuw4vOFCfFq27a1Dhw4pN27f7MuMCt4aMXuLi4l/xEjRqh+/fp68cUX9dprr6ms7OTDCwICAtS+fXvNnTtXt99+e7UEWt32HzyocX99Xvv2H1BYaKhaNm+qV1/4qzpd3a7imEVLsmQY0h96d7cuUC/x4YcLVT+ynp6Y8Iji4qK1fsNm9b15kHbu/NXq0LwC/Vd19F3VtWvXVulfp1V8fva5JyVJ777zkYYNG2tVWJbw9bf6Vfk+/5KSEhUUnKzWo6KiFBR0fveseuJ9/t7CE+/zB3B2nn6fv6er7vv8Tyyd7bZzhXQd4rZzuUuVn+0fFBRUqfl9AAC8DsP+AAD4GR+/1Y/kDwCAmY9X/rzYBwAAP0PlDwCAGcP+AAD4GYb9AQCAL6HyBwDAjGF/AAD8DMP+AADAl1D5AwBg5uOVP8kfAAAzH5/zZ9gfAAA/Q+UPAIAZw/4AAPgZHx/2J/kDAGDm45U/c/4AAPgZKn8AAMwY9gcAwM8w7A8AAHwJlT8AAGY+XvmT/AEAMDMMqyOoVgz7AwDgZ0j+AACYlZe7b3PBzJkz1bZtW4WHhys8PFyJiYlatGhRxX7DMJSSkqKGDRsqJCRE3bt314YNG1z+8Uj+AACYWZT8GzdurClTpignJ0c5OTnq2bOnbrnllooE/9xzz2nq1KmaMWOGVq1apdjYWPXu3VtHjx516To2w/CMiY2Sgm1Wh+C1Qhpea3UIAFxkDwyyOgSvVnh8R7We/8R7T7rtXCF3/fW8vh8ZGannn39e9913nxo2bKgxY8bo8ccflyQ5HA7FxMTo2Wef1bBhwyp9Tip/AADMjHL3bVVUVlamtLQ0FRYWKjExUdu3b1deXp769OlTcYzdble3bt2UnZ3t0rlZ7Q8AgJkbb/VzOBxyOBxObXa7XXa7/bTHr1u3TomJiSoqKlLdunW1YMECtW7duiLBx8TEOB0fExOjX375xaWYqPwBADAzDLdtqampioiIcNpSU1PPeOmLL75Ya9as0YoVK/TQQw9p8ODB+vHHHyv222w2U6jGKW3nQuUPAEA1GjdunJKTk53azlT1S1JwcLCaN28uSerQoYNWrVql6dOnV8zz5+XlKS4uruL4/Pz8U0YDzoXKHwAAMzeu9rfb7RW37v13O1vyNzMMQw6HQ02bNlVsbKwyMjIq9hUXFysrK0udOnVy6cej8gcAwMyix/uOHz9eSUlJio+P19GjR5WWlqbMzEylp6fLZrNpzJgxmjx5slq0aKEWLVpo8uTJqlOnju68806XruMxyb/5xf2sDsFrHX3zHqtD8FphD8y1OgT4qVYR8VaHAA+0d+9eDRo0SHv27FFERITatm2r9PR09e7dW5L02GOP6cSJExoxYoQOHjyojh07avHixQoLC3PpOh6T/AEA8BjncYve+XjrrbfOut9msyklJUUpKSnndR2SPwAAJka5Rzz/rtqw4A8AAD9D5Q8AgJlFC/5qCskfAAAzi+b8awrD/gAA+BkqfwAAzHx8wR/JHwAAM+b8AQDwMz6e/JnzBwDAz1D5AwBgZjDnDwCAf2HYHwAA+BIqfwAAzLjVDwAAP8MT/gAAgC+h8gcAwIxhfwAA/IvBan8AAOBLqPwBADBj2B8AAD/j46v9Sf4AAJj5eOXPnD8AAH6Gyh8AADMfX+1P8gcAwIxhfwAA4Euo/AEAMGO1PwAAfoZhfwAA4Euo/AEAMOHZ/n7q7ntvV/rSj7R+R7bW78jWgvR31P26LlaH5ZE+yN2mAW8sUefnF6rz8wt1z+xMLduaV7HfMAzNXPqjek//Sh2f/VT3v7NUW/cdsTBi7zB82GBt2bxcx478rJUrFqlL56utDslr0Heue/DRe5Wz51unLf3fn1odlnXKDfdtHojkfwZ7fturZ5+Zpr7X3aG+192h7G+/1xvvTleLi5tZHZrHiQkL0Z97tNG8+3po3n09dFVCA435cHlFgp+9/Ce9u3Kr/nL95Xrv3h6KqltbD81bpkJHicWRe64BA27W1BdSlDrlJXW4+notW/a9vvj8XcXHN7Q6NI9H31Xdz5u26fq2t1Rsf+o5xOqQUE1I/mfwz6+z9K8ly7T951+0/edf9Pykf+h44XG169DW6tA8TreWcbq2eawS6ocpoX6YRve4VHWCA7Xu1wMyDEPvfb9VD3S+WNdd0kjNoyP0177tdaKkTIs27LI6dI/1yMND9fasNL09631t2rRVj46dqF27f9PwYfdYHZrHo++qrrS0TPv3HajYDu0/ZHVI1qHyR61atdT31hsUUidEq3P+bXU4Hq2s3FD6hl06UVKmto0i9euh4yoodCjxopiKY4IDA9ShSZTW7D5gYaSeKygoSO3atVXGkiyn9oyMLCVe08GiqLwDfXd+mlzUWIt+WKDPVs7X5JkpatQkzuqQrGOUu2/zQG5f8Ldr1y5NnDhRb7/9trtPXeMubtVCC9Lfkb12sAoLj2vYPWO0ZfM2q8PySFvyD+ue2ZkqLi1XSHCgpv7xGjVrEK41u/dLkiJD7U7HR4batefIcStC9XhRUZEKDAxU/t4Cp/b8/ALFxEZbFJV3oO+qbv0PP2rinyfpl593qX6Derp/zGC99flMDex+jw4f9MM1Oh5asbuL25P/gQMHNGfOnLMmf4fDIYfD4dRmGOWy2TxrIGLb1u1K6j5A4RFhSurbSy+8/DcNvPk+/gA4jQvrh2n+A9fpaFGJ/rn5Vz31eY7evLtrxX6b6XjjNG1wZhjO//Ox2WyntOH06DvXZX+zsuLff94krc3ZoE9XpOmm25P03mvzLYwM1cHl5L9w4cKz7t+27dyJMTU1VU8//bRTW3jtaF1QJ+YM37BGSUmpftl+cl563ZofdfmVbXTvg3dp/KN/tTgyzxMUUEtNIutKki5tWE8bfjuoeau26t7EiyVJ+wsdahAWUnH8wUKHIkNrWxKrpysoOKDS0lLFxDZwam/QoL7y9+6zKCrvQN+5T9GJIv28cZvimza2OhRLGFT+zvr163fOv6JttrPXdOPGjVNycrJTW5sLO7kaSo2z2WwKtgdbHYZXMCQVl5Wr0QV1FBVq1/Lt+bok9gJJUklZuXJ2FmhMz0stjdFTlZSUaPXqtep1XVd99ll6RXuvXl31+edfWxiZ56Pv3CcoOEgXtkjQDyvXWh2KNUj+zuLi4vTyyy+rX79+p92/Zs0atW/f/qznsNvtstud54A9bcj//574szKXLNOeX/MUWjdUN/e/Qdd07qB7bn/I6tA8zkv/Wq8uzWIVEx6i48WlSt+wWzm/7NPLf+osm82mu65urre+26yEeqFqEllXb2ZvVkhQgJIujbc6dI/14vQ3NGfWdOXm/lsrVuZq6P13q0l8I732+jtWh+bx6LuqefipEfo2I1t5u/eqXlQ93T/mHoWGheqLDxdZHRqqgcvJv3379lq9evUZk7+vzK01aBCpF2dOUnRMAx09ckybfvxJ99z+kJZlrrA6NI9zoNChCQtzVHCsSHXtQWoZHa6X/9S5YoX/kMSWKiot0+T0NTpSVKLLGkVq5h2dFWoPsjhyz/XhhwtVP7KenpjwiOLiorV+w2b1vXmQdu781erQPB59VzUxcdGa9MpEXRAZoYP7D2n96g2696bhytu91+rQrOHjT/izGS5m6m+//VaFhYW64YYbTru/sLBQOTk56tatm0uBJNTn/vmq2vTijVaH4LXCHphrdQjwU1fUv8jqELxazp5vq/X8R0ckue1cYa9UfvQkNTVVn3zyiTZt2qSQkBB16tRJzz77rC6++OKKY4YMGaI5c+Y4fa9jx45asaLyxanLlf+111571v2hoaEuJ34AACBlZWVp5MiRuuqqq1RaWqoJEyaoT58++vHHHxUaGlpx3A033KBZs2ZVfA4Odm09Gi/2AQDAzKIFf+np6U6fZ82apejoaOXm5qpr199vn7bb7YqNja3ydTxrlR0AAB7AMAy3befj8OHDkqTIyEin9szMTEVHR6tly5YaOnSo8vPzXTovlT8AANXodA+2O91db2aGYSg5OVldunRRmzZtKtqTkpI0YMAAJSQkaPv27XryySfVs2dP5ebmnvOc/0XlDwCAmRtf7JOamqqIiAinLTU19ZwhjBo1SmvXrtX777/v1D5w4EDdeOONatOmjfr27atFixbpp59+0pdfflnpH4/KHwAAMzfO+Z/uwXbnqtBHjx6thQsXaunSpWrc+OxPWYyLi1NCQoK2bNlS6ZhI/gAAmLjz8b6VGeKvuK5haPTo0VqwYIEyMzPVtGnTc35n//792rVrl+LiKv8WRob9AQDwECNHjtS7776refPmKSwsTHl5ecrLy9OJEyckSceOHdPYsWO1fPly7dixQ5mZmerbt6+ioqJ06623Vvo6VP4AAJhZdKvfzJkzJUndu3d3ap81a5aGDBmigIAArVu3TnPnztWhQ4cUFxenHj16aP78+QoLC6v0dUj+AACYWfR033PdGhgSEqKvvz7/l1Qx7A8AgJ+h8gcAwMSdC/48EckfAAAzH0/+DPsDAOBnqPwBADCzaMFfTSH5AwBg4utz/gz7AwDgZ6j8AQAwY9gfAAD/4uvD/iR/AADMfLzyZ84fAAA/Q+UPAICJ4eOVP8kfAAAzH0/+DPsDAOBnqPwBADBh2B8AAH/j48mfYX8AAPwMlT8AACYM+wMA4GdI/gAA+BlfT/7M+QMA4Geo/AEAMDNsVkdQrTwm+Q8Mu9TqELxW2ANzrQ7Bax2ZdL3VIXi18AlfWx2C11qzf5vVIeAsGPYHAAA+xWMqfwAAPIVRzrA/AAB+hWF/AADgU6j8AQAwMVjtDwCAf2HYHwAA+BQqfwAATFjtDwCAnzEMqyOoXiR/AABMfL3yZ84fAAA/Q+UPAICJr1f+JH8AAEx8fc6fYX8AAPwMlT8AACYM+wMA4Gd8/fG+DPsDAOAhUlNTddVVVyksLEzR0dHq16+fNm/e7HSMYRhKSUlRw4YNFRISou7du2vDhg0uXYfkDwCAiVHuvs0VWVlZGjlypFasWKGMjAyVlpaqT58+KiwsrDjmueee09SpUzVjxgytWrVKsbGx6t27t44ePVrp6zDsDwCASblFw/7p6elOn2fNmqXo6Gjl5uaqa9euMgxD06ZN04QJE9S/f39J0pw5cxQTE6N58+Zp2LBhlboOlT8AANXI4XDoyJEjTpvD4ajUdw8fPixJioyMlCRt375deXl56tOnT8Uxdrtd3bp1U3Z2dqVjIvkDAGBiGDa3bampqYqIiHDaUlNTKxGDoeTkZHXp0kVt2rSRJOXl5UmSYmJinI6NiYmp2FcZDPsDAGDizlv9xo0bp+TkZKc2u91+zu+NGjVKa9eu1bJly07ZZ7M5x2cYxiltZ0PyBwDAxJ1P+LPb7ZVK9v9r9OjRWrhwoZYuXarGjRtXtMfGxko6OQIQFxdX0Z6fn3/KaMDZMOwPAICHMAxDo0aN0ieffKJvvvlGTZs2ddrftGlTxcbGKiMjo6KtuLhYWVlZ6tSpU6WvQ+UPAICJVU/4GzlypObNm6fPPvtMYWFhFfP4ERERCgkJkc1m05gxYzR58mS1aNFCLVq00OTJk1WnTh3deeedlb4OyR8AABOrbvWbOXOmJKl79+5O7bNmzdKQIUMkSY899phOnDihESNG6ODBg+rYsaMWL16ssLCwSl+H5A8AgIcwKrHYwGazKSUlRSkpKVW+DskfAAATX3+2P8kfAAATd67290Ss9gcAwM+Q/P+j6dWXaMibY/XEylf03I73dWmfDk7721x/le6f+xdNXP26ntvxvuJaJ1gUqfcYPmywtmxermNHftbKFYvUpfPVVofkcQI7/kH2u59UyMOvKGTENAX3GyVbvVjng4LsCrruLtUe/neFjHlVte/7mwKv6G5JvN6C372qo+9OKjdsbts8Ecn/P4Lr2LVn4059+tSsM+7/JecnLXr2/RqOzDsNGHCzpr6QotQpL6nD1ddr2bLv9cXn7yo+vqHVoXmUgPiLVfrDNyp6928q+vAF2WoFyD4gWQoKrjgmuMefFNC0jYq/fENFb09QSU6Ggq67SwHNr7AucA/G717V0Xe/c+fjfT0Ryf8/Nmf+W1+/8IHWf73qtPtXL1imJS99oi3fravhyLzTIw8P1duz0vT2rPe1adNWPTp2onbt/k3Dh91jdWgexfHRiyrb8J2M/b/J2LdLjkVvq1ZElGrFXFhxTK2GzVS6IVvluzbLOLJfZWuzZOTvUq2Ypmc+sR/jd6/q6Dv/QfKH2wUFBaldu7bKWJLl1J6RkaXEazqc4VuQJJs9RJJkFP3+7u6yX7cooNkVstW9QJJUK/4S2SJjVbZjvRUhejR+96qOvnNmGO7bPJHLq/1PnDih3NxcRUZGqnXr1k77ioqK9MEHH+iee87+V6LD4TjldYalRpkCbQGuhgMPFBUVqcDAQOXvLXBqz88vUExstEVReYegHgNVtvsnGQW/VrSV/HOegq8fopCHpsooK5UMQ8Vfz1b5r1ssjNQz8btXdfSdM0+dq3cXlyr/n376Sa1atVLXrl112WWXqXv37tqzZ0/F/sOHD+vee+8953lO93rDlYd/dD16eDTzwypsNlulHmDhr4J63a1aDeJV/PlrTu2B7XupVsNmcnwyXUXvPKOSzPkK7j1ItRJan+FM4Hev6ui7k5jz/x+PP/64LrvsMuXn52vz5s0KDw9X586dtXPnTpcuOm7cOB0+fNhp6xjB/8h8RUHBAZWWliomtoFTe4MG9ZW/d59FUXm2oOvuVECzK+SY/5yMYwd/3xEYpKBrb1Pxv9JU9vO/ZezbrdIfvlHZpu8VdNX11gXsofjdqzr6zr+4lPyzs7M1efJkRUVFqXnz5lq4cKGSkpJ07bXXatu2bZU+j91uV3h4uNPGkL/vKCkp0erVa9Xruq5O7b16ddXyFTkWReW5gq67SwEt2p9M/Iedh1xVK0C2gMBTJg4No1xy4d3d/oLfvaqj75z5+q1+Ls35nzhxQoGBzl95+eWXVatWLXXr1k3z5s1za3A1KbiOXfUv/P3+6sj4BoprnaATh47p0G/7FRIRqgsaRSkiup4kKfqik+9RPrrvkI7tO2xJzJ7sxelvaM6s6crN/bdWrMzV0PvvVpP4Rnrt9XesDs2jBPW6W4GtrpFjwUsySoqk0PCTOxwnpNISqbhIZTs3KbjbABWXFss4sl+1Gl+swNadVJKZZm3wHorfvaqj737n6xMdLiX/Sy65RDk5OWrVqpVT+z/+8Q8ZhqGbb77ZrcHVpMZtL9LwtKcqPvd98uSixZyPsvTB2FfVund7Dfz7QxX775rxsCQpY9pHypj2cc0G6wU+/HCh6kfW0xMTHlFcXLTWb9isvjcP0s6dv577y34k6MqekqTad/zFqd3x1Vsq2/DdyX//4lUFX/tHBd/4oGy1Q2Uc2a+SZZ+odE1mTYfrFfjdqzr6zn/YDBdWcqSmpurbb7/VV199ddr9I0aM0Kuvvqry8nKXA3nswjtc/g5OmvrbUqtD8FpHJjFvfj7CJ3xtdQjwU6XF1fsHSXbcbW47V6c9nlcgujTnP27cuDMmfkl65ZVXqpT4AQDwJKz2BwAAPoVX+gIAYOLrY9gkfwAATAx55nC9uzDsDwCAn6HyBwDApNzHb/Qn+QMAYFLu48P+JH8AAEyY8wcAAD6Fyh8AABNu9QMAwM8w7A8AAHwKlT8AACYM+wMA4Gd8Pfkz7A8AgJ+h8gcAwMTXF/yR/AEAMCn37dzPsD8AAP6Gyh8AABOe7Q8AgJ/x8Zf6kfwBADDjVj8AAOBTqPwBADAptzHnDwCAX/H1OX+G/QEA8DMkfwAATMrduLli6dKl6tu3rxo2bCibzaZPP/3Uaf+QIUNks9mctmuuucbln4/kDwCASbnNfZsrCgsLdfnll2vGjBlnPOaGG27Qnj17KravvvrK5Z+POX8AADxEUlKSkpKSznqM3W5XbGzseV2Hyh8AAJNy2dy2ORwOHTlyxGlzOBxVji0zM1PR0dFq2bKlhg4dqvz8fJfPQfIHAMDEcOOWmpqqiIgIpy01NbVKcSUlJem9997TN998oxdeeEGrVq1Sz549Xf5jgmF/AACq0bhx45ScnOzUZrfbq3SugQMHVvx7mzZt1KFDByUkJOjLL79U//79K30ej0n+3zh2Wx2C17IHBlkdgtcKn/C11SF4tWP/nGJ1CF6r/vVPWh0CzsKdr/S12+1VTvbnEhcXp4SEBG3ZssWl73lM8gcAwFN4y7P99+/fr127dikuLs6l75H8AQAwseoJf8eOHdPWrVsrPm/fvl1r1qxRZGSkIiMjlZKSottuu01xcXHasWOHxo8fr6ioKN16660uXYfkDwCAh8jJyVGPHj0qPv93rcDgwYM1c+ZMrVu3TnPnztWhQ4cUFxenHj16aP78+QoLC3PpOiR/AABM3Dnn74ru3bvLMM487vD11+5Zp0TyBwDAxFvm/KuK+/wBAPAzVP4AAJj4euVP8gcAwMSwaM6/pjDsDwCAn6HyBwDAhGF/AAD8jK8nf4b9AQDwM1T+AACYWPV435pC8gcAwMSqJ/zVFJI/AAAmzPkDAACfQuUPAICJr1f+JH8AAEx8fcEfw/4AAPgZKn8AAExY7Q8AgJ/x9Tl/hv0BAPAzVP4AAJj4+oI/kj8AACblPp7+GfYHAMDPUPkDAGDi6wv+SP4AAJj49qA/yR8AgFP4euXPnD8AAH6Gyh8AABOe8AcAgJ/x9Vv9SP5n8OCj9+rBsfc5tRXk79cNl/ezJiAv07nz1RrzyIO68srLFBcXo4EDH9QXny+2OiyvMnzYYD2aPFxxcdHa8ONPevTRiVr23fdWh+VRPvhXrj7IzNVv+w9Jkpo1bKBhfa9Vl8uaS5Jmfpal9FU/Ku/AEQUFBqh1QqxG3dpDbS9qZGHUnov/bv0Hyf8sft60TSNuf6Tic1m5ry8BcZ/Q0Dpat26j3nnnQ73//mtWh+N1Bgy4WVNfSNGo0eOVvXyVhj4wSF98/q4uu7y7du36zerwPEZ0vTA9fFtPxUfXkyR9nr1WD8/4QPOfGqrmjRooIba+xt15vRo3qKei4lK9m7FSD704T59PHqHIsFCLo/c8/Hf7O9+u+0n+Z1VaWqb9+w5YHYZXWrw4U4sXZ1odhtd65OGhentWmt6e9b4k6dGxE9WnTzcNH3aPJjwxxeLoPEf3K1o6fR7dv4c+yMzV2m271bxRA/2hYxun/WMH9taCZWu0ZXe+OrZqWpOhegX+u/2dr5d6rPY/iyYXNdaiHxbos5XzNXlmiho1ibM6JPiBoKAgtWvXVhlLspzaMzKylHhNB4ui8nxl5eVa9P0GnSgu0eXNGp+yv6S0TB8vXa2wELtaNo6xIELAc7hc+W/cuFErVqxQYmKiLrnkEm3atEnTp0+Xw+HQ3XffrZ49e57zHA6HQw6Hw6mt3ChXLZvn/C2y/ocfNfHPk/TLz7tUv0E93T9msN76fKYGdr9Hhw8esTo8+LCoqEgFBgYqf2+BU3t+foFiYqMtispzbdmdr0Gps1RcUqo69mC9OGKAmjVsULE/699b9Pjrn6iouERREWF6Nfku1QurY2HE8Aa+vuDPpWybnp6uK664QmPHjtWVV16p9PR0de3aVVu3btXOnTt1/fXX65tvvjnneVJTUxUREeG05R3bVeUfojpkf7NS33yZpZ83bdP33+bq4bsfkyTddHuSxZHBXxiG8/98bDbbKW2QLoytrw+eGqp3xt+rAd3b68m3F+rn3/ZV7L/qkgR98NRQzf3LEHVuc5H+77WPtf9IoYURwxsYbtw8kUvJ/5lnntH//d//af/+/Zo1a5buvPNODR06VBkZGVqyZIkee+wxTZly7vnIcePG6fDhw05bbN34Kv8QNaHoRJF+3rhN8U1PHU4E3Kmg4IBKS0sVE9vAqb1Bg/rK37vvDN/yX0GBAWoSE6lLL2yoh2/rqZbx0Xpvye93RdSxB6tJTKTaNmusp4f0VWCtWvp02RrrAgY8gEvJf8OGDRoyZIgk6fbbb9fRo0d12223Vey/4447tHbt2nOex263Kzw83GnzpCH/0wkKDtKFLRJUsHe/1aHAx5WUlGj16rXqdV1Xp/Zevbpq+Yoci6LyHoZxcn7/bPuLS0prMCJ4o3I3bp6oyqv9a9Wqpdq1a+uCCy6oaAsLC9Phw4fdEZflHn5qhL7NyFbe7r2qF1VP94+5R6Fhofriw0VWh+YVQkPrqFmzCys+X5gQr7ZtW+vAgUPavZtb1c7lxelvaM6s6crN/bdWrMzV0PvvVpP4Rnrt9XesDs2jvPTJN+rSprliIsN1vKhY6d9vUM7mX/TKmDt03FGsN79cpu6Xt1TUBXV1+NgJzf9XrvYePKLeHVpbHbpH4r/b3/n6nL9Lyf/CCy/U1q1b1bz5yQdoLF++XE2aNKnYv2vXLsXF+caK+Ji4aE16ZaIuiIzQwf2HtH71Bt1703Dl7d5rdWheoV27tkr/Oq3i87PPPSlJevedjzRs2FirwvIaH364UPUj6+mJCY8oLi5a6zdsVt+bB2nnzl+tDs2j7D9SqAlvfaZ9h4+pbohdLRtH65Uxdyjx0ovkKCnV9j37tTD7Yx06dlwXhIbo0qYNNevxwWreqMG5T+6H+O/2d76d+iWb4cIKoldffVXx8fG68cYbT7t/woQJ2rt3r958802XA+kQd63L38FJGw971mJJb+IoLbE6BK927J88c6Cq6l//pNUheLXC4zuq9fyPXPgnt53rxR1p5z6ohrlU+Q8fPvys+ydNmnRewQAA4Ak8da7eXTx7lR0AABYw3PiPK5YuXaq+ffuqYcOGstls+vTTT53jMgylpKSoYcOGCgkJUffu3bVhwwaXfz6SPwAAHqKwsFCXX365ZsyYcdr9zz33nKZOnaoZM2Zo1apVio2NVe/evXX06FGXrsOz/QEAMLFq2D8pKUlJSad/mJxhGJo2bZomTJig/v37S5LmzJmjmJgYzZs3T8OGDav0daj8AQAwKZfhts3hcOjIkSNOm/kR95Wxfft25eXlqU+fPhVtdrtd3bp1U3Z2tkvnIvkDAFCNTvdI+9TUVJfPk5eXJ0mKiXF+MVVMTEzFvspi2B8AABN33uc/btw4JScnO7XZ7fYqn89mszl9NgzjlLZzIfkDAGDizif82e3280r2/xUbGyvp5AjA/z5QLz8//5TRgHNh2B8AAC/QtGlTxcbGKiMjo6KtuLhYWVlZ6tSpk0vnovIHAMDEqtX+x44d09atWys+b9++XWvWrFFkZKSaNGmiMWPGaPLkyWrRooVatGihyZMnq06dOrrzzjtdug7JHwAAE1cfzuMuOTk56tGjR8Xn/64VGDx4sGbPnq3HHntMJ06c0IgRI3Tw4EF17NhRixcvVlhYmEvXIfkDAGBiVeXfvXt3ne2VOzabTSkpKUpJSTmv6zDnDwCAn6HyBwDAxKph/5pC8gcAwIS3+gEAAJ9C5Q8AgEn5WRbd+QKSPwAAJr6d+hn2BwDA71D5AwBg4s5n+3sikj8AACa+fqsfw/4AAPgZKn8AAEx8/T5/kj8AACbM+QMA4GeY8wcAAD6Fyh8AABPm/AEA8DOGjz/el2F/AAD8DJU/AAAmrPYHAMDPMOdfQ345nm91CF6ra/1WVofgtTL2rrU6BK9W97q/WB2C1zo0qr3VIcCPeUzyBwDAU/j6ff4kfwAATHx9zp/V/gAA+BkqfwAATHz9Pn+SPwAAJqz2BwDAz/j6gj/m/AEA8DNU/gAAmPj6an+SPwAAJr6+4I9hfwAA/AyVPwAAJgz7AwDgZ1jtDwAAfAqVPwAAJuU+vuCP5A8AgIlvp36G/QEA8DtU/gAAmLDaHwAAP0PyBwDAz/CEPwAAUCNSUlJks9mcttjYWLdfh8ofAAATK4f9L730Ui1ZsqTic0BAgNuvQfIHAMDEyif8BQYGVku1/78Y9gcAoBo5HA4dOXLEaXM4HGc8fsuWLWrYsKGaNm2qP/3pT9q2bZvbYyL5AwBgYhiG27bU1FRFREQ4bampqae9bseOHTV37lx9/fXXeuONN5SXl6dOnTpp//79bv35bIaHLGlsEHGx1SF4rQ7hF1kdgtfK2LvW6hDgpw6Nam91CF6t7tSF1Xr+dnFd3Hau5Tv+eUqlb7fbZbfbz/ndwsJCNWvWTI899piSk5PdFhNz/gAAVKPKJvrTCQ0N1WWXXaYtW7a4NSaG/QEAMHHnsP/5cDgc2rhxo+Li4tz0k51E8gcAwKRchts2V4wdO1ZZWVnavn27Vq5cqT/+8Y86cuSIBg8e7Nafj2F/AAA8xO7du3XHHXeooKBADRo00DXXXKMVK1YoISHBrdch+QMAYGLVff5paWk1ch2SPwAAJuWecSNctSH5n8HDyQ/qxr591KLFRTpRVKRVK3/QMxP/rp+3brc6NI83O3u2YuJjTmn/fM7neuWJVyyIyDsNHzZYjyYPV1xctDb8+JMefXSiln33vdVheQX67tyCrvujAi9LVK3oRjJKilW+Y5McX8yRse9Xp+Ns0Y1lv2mwApq1kWw2le/dpaI5z8o4VGBR5DXDyif81QSS/xl06ny13n7jPf2wep0CAwM0/slH9OGCt9Sl4406fvyE1eF5tIdveli1An5fS5pwcYJS30/Vt198a2FU3mXAgJs19YUUjRo9XtnLV2noA4P0xefv6rLLu2vXrt+sDs+j0XeVE9CsjUq++1LlO7dIAQEKThqkkGFP6/hzI6Xik/ek2+rHqs7oKSpZuUTFX78v40ShasXES6UlFkeP8+WWh/wYhiGbzXZe5/D0h/zUr19Pm7at0M1Jd2l5do7V4Tjx9If8DJs4TFf3ulr3X3u/1aGcwlMf8pO97HOt/mG9Ro0eV9G2bm2mFi5M14QnplgYmefzlr7zuIf8hIar7l/f1fEZ41S+bYMkyT5orFRWJse8Fy0O7lTV/ZCfVtFXu+1cG/M9b9TJLbf62e12bdy40R2n8ljhEWGSpIMHD1sciXcJDApUj/49tHj+YqtD8RpBQUFq166tMpZkObVnZGQp8ZoOFkXlHei7qrOFhJ78l+NH/9NgU2CrDirf95tqP5iiOk/PVcjDzyugTUfrgqxBhhv/8UQuDfuf6dGCZWVlmjJliurXry9Jmjp16lnP43A4TnnUoWGUy2bz3McOPDNpnFZk52jTRvc+ZcnXJV6fqLrhdZXxYYbVoXiNqKhIBQYGKn+v85xqfn6BYmKjLYrKO9B3VWe/+T6Vbdug8rydkiRb3QjZatdRcM/bVLzoXRV/MUcBl7RT7SHjdGLmBJX/vMHiiHE+XEr+06ZN0+WXX64LLrjAqd0wDG3cuFGhoaGVGv5PTU3V008/7dQWEhyp0NpRroRTY579+1NqfWlL3XTDnVaH4nWu/9P1yvlXjg7sPWB1KF7HPCNns9nO+2lh/oK+c01w/2Gq1fBCnfjHX35v/E8xVrphpUqWnhxiL/9tuwIuvERBiUly+HjyZ7X//5g0aZLeeOMNvfDCC+rZs2dFe1BQkGbPnq3WrVtX6jzjxo07ZRThosYeNv/1H6nPPaHrk3rq5j/crT2/7bU6HK8S3ShaV3S5Qn978G9Wh+JVCgoOqLS0VDGxDZzaGzSor/y9+yyKyjvQd64LvvVBBV56tU68PF7G4d/fHGcUHpFRVqryvF1Ox5fn71ZA08r9v96beepwvbu4NM4+btw4zZ8/Xw899JDGjh2rkpKqrfi02+0KDw932jxxyH/K80/qxr591L/vYO38ZbfV4Xid3rf31uGCw/r+n5632MWTlZSUaPXqtep1XVen9l69umr5Cs9abOpp6DvXBPcfpsC2iTox8wkZB0zFTVmpynduUa3oRk7NtRo0VPnB/BqMEtXB5Yx71VVXKTc3V/v27VOHDh20bt26817p74mefWGi/nj7zRr+wKM6dqxQ0dFRio6OUu3aVXszk7+x2WzqfXtvLfloicrLyq0Ox+u8OP0N3X/fHRoyeKAuuaS5Xng+RU3iG+m119+xOjSPR99Vjv224Qpq301F7/5dcpyQLewC2cIukIKCK44pzlygwCu6KPCaPrJFxSmoy40KaH21Sr77yrrAa0i5Ybht80RVus+/bt26mjNnjtLS0tS7d2+VlZW5Oy7L3ffAyfn9z75616l99EN/Udq8BVaE5FWuvPZKxTSOYZV/FX344ULVj6ynJyY8ori4aK3fsFl9bx6knTt/PfeX/Rx9VzlBnf8gSaozMtWpvej9aSpd9Y0kqWzdCjk+mqng6/4o261DVZ7/q4pmT1H5dt++u0vy/WH/877Pf/fu3crNzVWvXr0UGhpa5fN4+n3+nszT7/P3ZJ56nz98n8fd5+9lqvs+/4uirnTbubYV/OC2c7nLeT/hr3HjxmrcuLE7YgEAwCMYhm9PV/J4XwAATMp9fNif5A8AgImvPxfC8+6vAwAA1YrKHwAAE4b9AQDwMwz7AwAAn0LlDwCAiac+mc9dSP4AAJj4+hP+GPYHAMDPUPkDAGDi6wv+SP4AAJj4+q1+DPsDAOBnqPwBADBh2B8AAD/DrX4AAPgZX6/8mfMHAMDPUPkDAGDi66v9Sf4AAJgw7A8AAHwKlT8AACas9gcAwM/wYh8AAOBTqPwBADBh2B8AAD/Dan8AAOBTqPwBADBhwR8AAH7GMAy3ba565ZVX1LRpU9WuXVvt27fXt99+6/afj+QPAICJVcl//vz5GjNmjCZMmKAffvhB1157rZKSkrRz5063/nwkfwAAPMTUqVN1//3364EHHlCrVq00bdo0xcfHa+bMmW69DskfAAATw42bw+HQkSNHnDaHw3HKNYuLi5Wbm6s+ffo4tffp00fZ2dlu/gFxVkVFRcbEiRONoqIiq0PxSvRf1dF3VUffnR/6z70mTpx4yt8EEydOPOW4X3/91ZBkfPfdd07tkyZNMlq2bOnWmGyG4eM3M56nI0eOKCIiQocPH1Z4eLjV4Xgd+q/q6Luqo+/OD/3nXg6H45RK3263y263O7X99ttvatSokbKzs5WYmFjRPmnSJL3zzjvatGmT22LiVj8AAKrR6RL96URFRSkgIEB5eXlO7fn5+YqJiXFrTMz5AwDgAYKDg9W+fXtlZGQ4tWdkZKhTp05uvRaVPwAAHiI5OVmDBg1Shw4dlJiYqNdff107d+7U8OHD3Xodkv852O12TZw4sVJDNjgV/Vd19F3V0Xfnh/6zzsCBA7V//34988wz2rNnj9q0aaOvvvpKCQkJbr0OC/4AAPAzzPkDAOBnSP4AAPgZkj8AAH6G5A8AgJ8h+Z9DTbxa0RctXbpUffv2VcOGDWWz2fTpp59aHZLXSE1N1VVXXaWwsDBFR0erX79+2rx5s9VheYWZM2eqbdu2Cg8PV3h4uBITE7Vo0SKrw/JKqampstlsGjNmjNWhoBqQ/M+ipl6t6IsKCwt1+eWXa8aMGVaH4nWysrI0cuRIrVixQhkZGSotLVWfPn1UWFhodWger3HjxpoyZYpycnKUk5Ojnj176pZbbtGGDRusDs2rrFq1Sq+//rratm1rdSioJtzqdxYdO3ZUu3btnF6l2KpVK/Xr10+pqakWRuZdbDabFixYoH79+lkdilfat2+foqOjlZWVpa5du1odjteJjIzU888/r/vvv9/qULzCsWPH1K5dO73yyiv629/+piuuuELTpk2zOiy4GZX/GdToqxWBszh8+LCkk0kMlVdWVqa0tDQVFhY6vSQFZzdy5EjdeOON6tWrl9WhoBrxhL8zKCgoUFlZ2SkvU4iJiTnlpQtAdTEMQ8nJyerSpYvatGljdTheYd26dUpMTFRRUZHq1q2rBQsWqHXr1laH5RXS0tK0evVqrVq1yupQUM1I/udgs9mcPhuGcUobUF1GjRqltWvXatmyZVaH4jUuvvhirVmzRocOHdLHH3+swYMHKysriz8AzmHXrl16+OGHtXjxYtWuXdvqcFDNSP5nUJOvVgROZ/To0Vq4cKGWLl2qxo0bWx2O1wgODlbz5s0lSR06dNCqVas0ffp0vfbaaxZH5tlyc3OVn5+v9u3bV7SVlZVp6dKlmjFjhhwOhwICAiyMEO7EnP8Z1OSrFYH/ZRiGRo0apU8++UTffPONmjZtanVIXs0wDDkcDqvD8HjXXXed1q1bpzVr1lRsHTp00F133aU1a9aQ+H0Mlf9Z1NSrFX3RsWPHtHXr1orP27dv15o1axQZGakmTZpYGJnnGzlypObNm6fPPvtMYWFhFaNPERERCgkJsTg6zzZ+/HglJSUpPj5eR48eVVpamjIzM5Wenm51aB4vLCzslHUloaGhql+/PutNfBDJ/yxq6tWKvignJ0c9evSo+JycnCxJGjx4sGbPnm1RVN7hv7eWdu/e3al91qxZGjJkSM0H5EX27t2rQYMGac+ePYqIiFDbtm2Vnp6u3r17Wx0a4FG4zx8AAD/DnD8AAH6G5A8AgJ8h+QMA4GdI/gAA+BmSPwAAfobkDwCAnyH5AwDgZ0j+AAD4GZI/AAB+huQPAICfIfkDAOBnSP4AAPiZ/wdAd5X+WcL37AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(evaluation[\"Actual\"],evaluation[\"Predict\"]),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Label_encoder_5.pkl\",'wb') as file:\n",
    "    pickle.dump(od_encode,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
